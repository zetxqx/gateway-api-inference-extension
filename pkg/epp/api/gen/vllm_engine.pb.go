// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v3.21.12
// source: vllm_engine.proto

package gen

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Sampling parameters for text generation
type SamplingParams struct {
	state                      protoimpl.MessageState `protogen:"open.v1"`
	Temperature                *float32               `protobuf:"fixed32,1,opt,name=temperature,proto3,oneof" json:"temperature,omitempty"`
	TopP                       float32                `protobuf:"fixed32,2,opt,name=top_p,json=topP,proto3" json:"top_p,omitempty"`
	TopK                       uint32                 `protobuf:"varint,3,opt,name=top_k,json=topK,proto3" json:"top_k,omitempty"`
	MinP                       float32                `protobuf:"fixed32,4,opt,name=min_p,json=minP,proto3" json:"min_p,omitempty"`
	FrequencyPenalty           float32                `protobuf:"fixed32,5,opt,name=frequency_penalty,json=frequencyPenalty,proto3" json:"frequency_penalty,omitempty"`
	PresencePenalty            float32                `protobuf:"fixed32,6,opt,name=presence_penalty,json=presencePenalty,proto3" json:"presence_penalty,omitempty"`
	RepetitionPenalty          float32                `protobuf:"fixed32,7,opt,name=repetition_penalty,json=repetitionPenalty,proto3" json:"repetition_penalty,omitempty"`
	MaxTokens                  *uint32                `protobuf:"varint,8,opt,name=max_tokens,json=maxTokens,proto3,oneof" json:"max_tokens,omitempty"`
	MinTokens                  uint32                 `protobuf:"varint,9,opt,name=min_tokens,json=minTokens,proto3" json:"min_tokens,omitempty"`
	Stop                       []string               `protobuf:"bytes,10,rep,name=stop,proto3" json:"stop,omitempty"`
	StopTokenIds               []uint32               `protobuf:"varint,11,rep,packed,name=stop_token_ids,json=stopTokenIds,proto3" json:"stop_token_ids,omitempty"`
	SkipSpecialTokens          bool                   `protobuf:"varint,12,opt,name=skip_special_tokens,json=skipSpecialTokens,proto3" json:"skip_special_tokens,omitempty"`
	SpacesBetweenSpecialTokens bool                   `protobuf:"varint,13,opt,name=spaces_between_special_tokens,json=spacesBetweenSpecialTokens,proto3" json:"spaces_between_special_tokens,omitempty"`
	IgnoreEos                  bool                   `protobuf:"varint,14,opt,name=ignore_eos,json=ignoreEos,proto3" json:"ignore_eos,omitempty"`
	N                          uint32                 `protobuf:"varint,15,opt,name=n,proto3" json:"n,omitempty"` // Number of parallel samples
	// Logprobs configuration
	Logprobs       *int32 `protobuf:"varint,22,opt,name=logprobs,proto3,oneof" json:"logprobs,omitempty"`                                   // Number of log probabilities per output token (-1 for all)
	PromptLogprobs *int32 `protobuf:"varint,23,opt,name=prompt_logprobs,json=promptLogprobs,proto3,oneof" json:"prompt_logprobs,omitempty"` // Number of log probabilities per prompt token (-1 for all)
	// Additional vLLM fields
	Seed                   *int32            `protobuf:"varint,24,opt,name=seed,proto3,oneof" json:"seed,omitempty"`                                                                                                  // Random seed for reproducibility
	IncludeStopStrInOutput bool              `protobuf:"varint,25,opt,name=include_stop_str_in_output,json=includeStopStrInOutput,proto3" json:"include_stop_str_in_output,omitempty"`                                // Whether to include stop strings in output
	LogitBias              map[int32]float32 `protobuf:"bytes,26,rep,name=logit_bias,json=logitBias,proto3" json:"logit_bias,omitempty" protobuf_key:"varint,1,opt,name=key" protobuf_val:"fixed32,2,opt,name=value"` // Token ID to bias mapping (-100 to 100)
	TruncatePromptTokens   *int32            `protobuf:"varint,27,opt,name=truncate_prompt_tokens,json=truncatePromptTokens,proto3,oneof" json:"truncate_prompt_tokens,omitempty"`                                    // Prompt truncation (-1 for model max)
	// Structured outputs (one of) - matches vLLM's StructuredOutputsParams
	//
	// Types that are valid to be assigned to Constraint:
	//
	//	*SamplingParams_JsonSchema
	//	*SamplingParams_Regex
	//	*SamplingParams_Grammar
	//	*SamplingParams_StructuralTag
	//	*SamplingParams_JsonObject
	//	*SamplingParams_Choice
	Constraint    isSamplingParams_Constraint `protobuf_oneof:"constraint"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SamplingParams) Reset() {
	*x = SamplingParams{}
	mi := &file_vllm_engine_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SamplingParams) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SamplingParams) ProtoMessage() {}

func (x *SamplingParams) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SamplingParams.ProtoReflect.Descriptor instead.
func (*SamplingParams) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{0}
}

func (x *SamplingParams) GetTemperature() float32 {
	if x != nil && x.Temperature != nil {
		return *x.Temperature
	}
	return 0
}

func (x *SamplingParams) GetTopP() float32 {
	if x != nil {
		return x.TopP
	}
	return 0
}

func (x *SamplingParams) GetTopK() uint32 {
	if x != nil {
		return x.TopK
	}
	return 0
}

func (x *SamplingParams) GetMinP() float32 {
	if x != nil {
		return x.MinP
	}
	return 0
}

func (x *SamplingParams) GetFrequencyPenalty() float32 {
	if x != nil {
		return x.FrequencyPenalty
	}
	return 0
}

func (x *SamplingParams) GetPresencePenalty() float32 {
	if x != nil {
		return x.PresencePenalty
	}
	return 0
}

func (x *SamplingParams) GetRepetitionPenalty() float32 {
	if x != nil {
		return x.RepetitionPenalty
	}
	return 0
}

func (x *SamplingParams) GetMaxTokens() uint32 {
	if x != nil && x.MaxTokens != nil {
		return *x.MaxTokens
	}
	return 0
}

func (x *SamplingParams) GetMinTokens() uint32 {
	if x != nil {
		return x.MinTokens
	}
	return 0
}

func (x *SamplingParams) GetStop() []string {
	if x != nil {
		return x.Stop
	}
	return nil
}

func (x *SamplingParams) GetStopTokenIds() []uint32 {
	if x != nil {
		return x.StopTokenIds
	}
	return nil
}

func (x *SamplingParams) GetSkipSpecialTokens() bool {
	if x != nil {
		return x.SkipSpecialTokens
	}
	return false
}

func (x *SamplingParams) GetSpacesBetweenSpecialTokens() bool {
	if x != nil {
		return x.SpacesBetweenSpecialTokens
	}
	return false
}

func (x *SamplingParams) GetIgnoreEos() bool {
	if x != nil {
		return x.IgnoreEos
	}
	return false
}

func (x *SamplingParams) GetN() uint32 {
	if x != nil {
		return x.N
	}
	return 0
}

func (x *SamplingParams) GetLogprobs() int32 {
	if x != nil && x.Logprobs != nil {
		return *x.Logprobs
	}
	return 0
}

func (x *SamplingParams) GetPromptLogprobs() int32 {
	if x != nil && x.PromptLogprobs != nil {
		return *x.PromptLogprobs
	}
	return 0
}

func (x *SamplingParams) GetSeed() int32 {
	if x != nil && x.Seed != nil {
		return *x.Seed
	}
	return 0
}

func (x *SamplingParams) GetIncludeStopStrInOutput() bool {
	if x != nil {
		return x.IncludeStopStrInOutput
	}
	return false
}

func (x *SamplingParams) GetLogitBias() map[int32]float32 {
	if x != nil {
		return x.LogitBias
	}
	return nil
}

func (x *SamplingParams) GetTruncatePromptTokens() int32 {
	if x != nil && x.TruncatePromptTokens != nil {
		return *x.TruncatePromptTokens
	}
	return 0
}

func (x *SamplingParams) GetConstraint() isSamplingParams_Constraint {
	if x != nil {
		return x.Constraint
	}
	return nil
}

func (x *SamplingParams) GetJsonSchema() string {
	if x != nil {
		if x, ok := x.Constraint.(*SamplingParams_JsonSchema); ok {
			return x.JsonSchema
		}
	}
	return ""
}

func (x *SamplingParams) GetRegex() string {
	if x != nil {
		if x, ok := x.Constraint.(*SamplingParams_Regex); ok {
			return x.Regex
		}
	}
	return ""
}

func (x *SamplingParams) GetGrammar() string {
	if x != nil {
		if x, ok := x.Constraint.(*SamplingParams_Grammar); ok {
			return x.Grammar
		}
	}
	return ""
}

func (x *SamplingParams) GetStructuralTag() string {
	if x != nil {
		if x, ok := x.Constraint.(*SamplingParams_StructuralTag); ok {
			return x.StructuralTag
		}
	}
	return ""
}

func (x *SamplingParams) GetJsonObject() bool {
	if x != nil {
		if x, ok := x.Constraint.(*SamplingParams_JsonObject); ok {
			return x.JsonObject
		}
	}
	return false
}

func (x *SamplingParams) GetChoice() *ChoiceConstraint {
	if x != nil {
		if x, ok := x.Constraint.(*SamplingParams_Choice); ok {
			return x.Choice
		}
	}
	return nil
}

type isSamplingParams_Constraint interface {
	isSamplingParams_Constraint()
}

type SamplingParams_JsonSchema struct {
	JsonSchema string `protobuf:"bytes,16,opt,name=json_schema,json=jsonSchema,proto3,oneof"` // JSON schema for structured output
}

type SamplingParams_Regex struct {
	Regex string `protobuf:"bytes,17,opt,name=regex,proto3,oneof"` // Regex pattern
}

type SamplingParams_Grammar struct {
	Grammar string `protobuf:"bytes,18,opt,name=grammar,proto3,oneof"` // Grammar/EBNF for structured output
}

type SamplingParams_StructuralTag struct {
	StructuralTag string `protobuf:"bytes,19,opt,name=structural_tag,json=structuralTag,proto3,oneof"` // Structural tag (e.g., Harmony models)
}

type SamplingParams_JsonObject struct {
	JsonObject bool `protobuf:"varint,20,opt,name=json_object,json=jsonObject,proto3,oneof"` // Force JSON object output
}

type SamplingParams_Choice struct {
	Choice *ChoiceConstraint `protobuf:"bytes,21,opt,name=choice,proto3,oneof"` // List of allowed choices
}

func (*SamplingParams_JsonSchema) isSamplingParams_Constraint() {}

func (*SamplingParams_Regex) isSamplingParams_Constraint() {}

func (*SamplingParams_Grammar) isSamplingParams_Constraint() {}

func (*SamplingParams_StructuralTag) isSamplingParams_Constraint() {}

func (*SamplingParams_JsonObject) isSamplingParams_Constraint() {}

func (*SamplingParams_Choice) isSamplingParams_Constraint() {}

// Choice constraint for structured outputs
type ChoiceConstraint struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Choices       []string               `protobuf:"bytes,1,rep,name=choices,proto3" json:"choices,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ChoiceConstraint) Reset() {
	*x = ChoiceConstraint{}
	mi := &file_vllm_engine_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ChoiceConstraint) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ChoiceConstraint) ProtoMessage() {}

func (x *ChoiceConstraint) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ChoiceConstraint.ProtoReflect.Descriptor instead.
func (*ChoiceConstraint) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{1}
}

func (x *ChoiceConstraint) GetChoices() []string {
	if x != nil {
		return x.Choices
	}
	return nil
}

// Pre-tokenized input from Rust router
type TokenizedInput struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	OriginalText  string                 `protobuf:"bytes,1,opt,name=original_text,json=originalText,proto3" json:"original_text,omitempty"` // For reference/debugging
	InputIds      []uint32               `protobuf:"varint,2,rep,packed,name=input_ids,json=inputIds,proto3" json:"input_ids,omitempty"`     // Actual token IDs to process
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TokenizedInput) Reset() {
	*x = TokenizedInput{}
	mi := &file_vllm_engine_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TokenizedInput) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TokenizedInput) ProtoMessage() {}

func (x *TokenizedInput) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TokenizedInput.ProtoReflect.Descriptor instead.
func (*TokenizedInput) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{2}
}

func (x *TokenizedInput) GetOriginalText() string {
	if x != nil {
		return x.OriginalText
	}
	return ""
}

func (x *TokenizedInput) GetInputIds() []uint32 {
	if x != nil {
		return x.InputIds
	}
	return nil
}

type GenerateRequest struct {
	state     protoimpl.MessageState `protogen:"open.v1"`
	RequestId string                 `protobuf:"bytes,1,opt,name=request_id,json=requestId,proto3" json:"request_id,omitempty"`
	// Prompt input
	//
	// Types that are valid to be assigned to Input:
	//
	//	*GenerateRequest_Tokenized
	//	*GenerateRequest_Text
	Input isGenerateRequest_Input `protobuf_oneof:"input"`
	// Generation parameters (includes logprobs config)
	SamplingParams *SamplingParams `protobuf:"bytes,4,opt,name=sampling_params,json=samplingParams,proto3" json:"sampling_params,omitempty"`
	// Streaming
	Stream        bool `protobuf:"varint,5,opt,name=stream,proto3" json:"stream,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerateRequest) Reset() {
	*x = GenerateRequest{}
	mi := &file_vllm_engine_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerateRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerateRequest) ProtoMessage() {}

func (x *GenerateRequest) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerateRequest.ProtoReflect.Descriptor instead.
func (*GenerateRequest) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{3}
}

func (x *GenerateRequest) GetRequestId() string {
	if x != nil {
		return x.RequestId
	}
	return ""
}

func (x *GenerateRequest) GetInput() isGenerateRequest_Input {
	if x != nil {
		return x.Input
	}
	return nil
}

func (x *GenerateRequest) GetTokenized() *TokenizedInput {
	if x != nil {
		if x, ok := x.Input.(*GenerateRequest_Tokenized); ok {
			return x.Tokenized
		}
	}
	return nil
}

func (x *GenerateRequest) GetText() string {
	if x != nil {
		if x, ok := x.Input.(*GenerateRequest_Text); ok {
			return x.Text
		}
	}
	return ""
}

func (x *GenerateRequest) GetSamplingParams() *SamplingParams {
	if x != nil {
		return x.SamplingParams
	}
	return nil
}

func (x *GenerateRequest) GetStream() bool {
	if x != nil {
		return x.Stream
	}
	return false
}

type isGenerateRequest_Input interface {
	isGenerateRequest_Input()
}

type GenerateRequest_Tokenized struct {
	Tokenized *TokenizedInput `protobuf:"bytes,2,opt,name=tokenized,proto3,oneof"`
}

type GenerateRequest_Text struct {
	Text string `protobuf:"bytes,3,opt,name=text,proto3,oneof"`
}

func (*GenerateRequest_Tokenized) isGenerateRequest_Input() {}

func (*GenerateRequest_Text) isGenerateRequest_Input() {}

type GenerateResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Response:
	//
	//	*GenerateResponse_Chunk
	//	*GenerateResponse_Complete
	Response      isGenerateResponse_Response `protobuf_oneof:"response"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerateResponse) Reset() {
	*x = GenerateResponse{}
	mi := &file_vllm_engine_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerateResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerateResponse) ProtoMessage() {}

func (x *GenerateResponse) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerateResponse.ProtoReflect.Descriptor instead.
func (*GenerateResponse) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{4}
}

func (x *GenerateResponse) GetResponse() isGenerateResponse_Response {
	if x != nil {
		return x.Response
	}
	return nil
}

func (x *GenerateResponse) GetChunk() *GenerateStreamChunk {
	if x != nil {
		if x, ok := x.Response.(*GenerateResponse_Chunk); ok {
			return x.Chunk
		}
	}
	return nil
}

func (x *GenerateResponse) GetComplete() *GenerateComplete {
	if x != nil {
		if x, ok := x.Response.(*GenerateResponse_Complete); ok {
			return x.Complete
		}
	}
	return nil
}

type isGenerateResponse_Response interface {
	isGenerateResponse_Response()
}

type GenerateResponse_Chunk struct {
	Chunk *GenerateStreamChunk `protobuf:"bytes,1,opt,name=chunk,proto3,oneof"` // For streaming
}

type GenerateResponse_Complete struct {
	Complete *GenerateComplete `protobuf:"bytes,2,opt,name=complete,proto3,oneof"` // For final/non-streaming
}

func (*GenerateResponse_Chunk) isGenerateResponse_Response() {}

func (*GenerateResponse_Complete) isGenerateResponse_Response() {}

type GenerateStreamChunk struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	TokenIds         []uint32               `protobuf:"varint,1,rep,packed,name=token_ids,json=tokenIds,proto3" json:"token_ids,omitempty"` // Incremental tokens
	PromptTokens     uint32                 `protobuf:"varint,2,opt,name=prompt_tokens,json=promptTokens,proto3" json:"prompt_tokens,omitempty"`
	CompletionTokens uint32                 `protobuf:"varint,3,opt,name=completion_tokens,json=completionTokens,proto3" json:"completion_tokens,omitempty"`
	CachedTokens     uint32                 `protobuf:"varint,4,opt,name=cached_tokens,json=cachedTokens,proto3" json:"cached_tokens,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *GenerateStreamChunk) Reset() {
	*x = GenerateStreamChunk{}
	mi := &file_vllm_engine_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerateStreamChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerateStreamChunk) ProtoMessage() {}

func (x *GenerateStreamChunk) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerateStreamChunk.ProtoReflect.Descriptor instead.
func (*GenerateStreamChunk) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{5}
}

func (x *GenerateStreamChunk) GetTokenIds() []uint32 {
	if x != nil {
		return x.TokenIds
	}
	return nil
}

func (x *GenerateStreamChunk) GetPromptTokens() uint32 {
	if x != nil {
		return x.PromptTokens
	}
	return 0
}

func (x *GenerateStreamChunk) GetCompletionTokens() uint32 {
	if x != nil {
		return x.CompletionTokens
	}
	return 0
}

func (x *GenerateStreamChunk) GetCachedTokens() uint32 {
	if x != nil {
		return x.CachedTokens
	}
	return 0
}

type GenerateComplete struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	OutputIds        []uint32               `protobuf:"varint,1,rep,packed,name=output_ids,json=outputIds,proto3" json:"output_ids,omitempty"`  // All output tokens
	FinishReason     string                 `protobuf:"bytes,2,opt,name=finish_reason,json=finishReason,proto3" json:"finish_reason,omitempty"` // "stop", "length", "abort"
	PromptTokens     uint32                 `protobuf:"varint,3,opt,name=prompt_tokens,json=promptTokens,proto3" json:"prompt_tokens,omitempty"`
	CompletionTokens uint32                 `protobuf:"varint,4,opt,name=completion_tokens,json=completionTokens,proto3" json:"completion_tokens,omitempty"`
	CachedTokens     uint32                 `protobuf:"varint,5,opt,name=cached_tokens,json=cachedTokens,proto3" json:"cached_tokens,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *GenerateComplete) Reset() {
	*x = GenerateComplete{}
	mi := &file_vllm_engine_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerateComplete) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerateComplete) ProtoMessage() {}

func (x *GenerateComplete) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerateComplete.ProtoReflect.Descriptor instead.
func (*GenerateComplete) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{6}
}

func (x *GenerateComplete) GetOutputIds() []uint32 {
	if x != nil {
		return x.OutputIds
	}
	return nil
}

func (x *GenerateComplete) GetFinishReason() string {
	if x != nil {
		return x.FinishReason
	}
	return ""
}

func (x *GenerateComplete) GetPromptTokens() uint32 {
	if x != nil {
		return x.PromptTokens
	}
	return 0
}

func (x *GenerateComplete) GetCompletionTokens() uint32 {
	if x != nil {
		return x.CompletionTokens
	}
	return 0
}

func (x *GenerateComplete) GetCachedTokens() uint32 {
	if x != nil {
		return x.CachedTokens
	}
	return 0
}

type EmbedRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	RequestId     string                 `protobuf:"bytes,1,opt,name=request_id,json=requestId,proto3" json:"request_id,omitempty"`
	Tokenized     *TokenizedInput        `protobuf:"bytes,2,opt,name=tokenized,proto3" json:"tokenized,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *EmbedRequest) Reset() {
	*x = EmbedRequest{}
	mi := &file_vllm_engine_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EmbedRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EmbedRequest) ProtoMessage() {}

func (x *EmbedRequest) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EmbedRequest.ProtoReflect.Descriptor instead.
func (*EmbedRequest) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{7}
}

func (x *EmbedRequest) GetRequestId() string {
	if x != nil {
		return x.RequestId
	}
	return ""
}

func (x *EmbedRequest) GetTokenized() *TokenizedInput {
	if x != nil {
		return x.Tokenized
	}
	return nil
}

type EmbedResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Embedding     []float32              `protobuf:"fixed32,1,rep,packed,name=embedding,proto3" json:"embedding,omitempty"`
	PromptTokens  uint32                 `protobuf:"varint,2,opt,name=prompt_tokens,json=promptTokens,proto3" json:"prompt_tokens,omitempty"`
	EmbeddingDim  uint32                 `protobuf:"varint,3,opt,name=embedding_dim,json=embeddingDim,proto3" json:"embedding_dim,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *EmbedResponse) Reset() {
	*x = EmbedResponse{}
	mi := &file_vllm_engine_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *EmbedResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*EmbedResponse) ProtoMessage() {}

func (x *EmbedResponse) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use EmbedResponse.ProtoReflect.Descriptor instead.
func (*EmbedResponse) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{8}
}

func (x *EmbedResponse) GetEmbedding() []float32 {
	if x != nil {
		return x.Embedding
	}
	return nil
}

func (x *EmbedResponse) GetPromptTokens() uint32 {
	if x != nil {
		return x.PromptTokens
	}
	return 0
}

func (x *EmbedResponse) GetEmbeddingDim() uint32 {
	if x != nil {
		return x.EmbeddingDim
	}
	return 0
}

type HealthCheckRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckRequest) Reset() {
	*x = HealthCheckRequest{}
	mi := &file_vllm_engine_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckRequest) ProtoMessage() {}

func (x *HealthCheckRequest) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckRequest.ProtoReflect.Descriptor instead.
func (*HealthCheckRequest) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{9}
}

type HealthCheckResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Healthy       bool                   `protobuf:"varint,1,opt,name=healthy,proto3" json:"healthy,omitempty"`
	Message       string                 `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthCheckResponse) Reset() {
	*x = HealthCheckResponse{}
	mi := &file_vllm_engine_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthCheckResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthCheckResponse) ProtoMessage() {}

func (x *HealthCheckResponse) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthCheckResponse.ProtoReflect.Descriptor instead.
func (*HealthCheckResponse) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{10}
}

func (x *HealthCheckResponse) GetHealthy() bool {
	if x != nil {
		return x.Healthy
	}
	return false
}

func (x *HealthCheckResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

type AbortRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	RequestIds    []string               `protobuf:"bytes,1,rep,name=request_ids,json=requestIds,proto3" json:"request_ids,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AbortRequest) Reset() {
	*x = AbortRequest{}
	mi := &file_vllm_engine_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AbortRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AbortRequest) ProtoMessage() {}

func (x *AbortRequest) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AbortRequest.ProtoReflect.Descriptor instead.
func (*AbortRequest) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{11}
}

func (x *AbortRequest) GetRequestIds() []string {
	if x != nil {
		return x.RequestIds
	}
	return nil
}

type AbortResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AbortResponse) Reset() {
	*x = AbortResponse{}
	mi := &file_vllm_engine_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AbortResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AbortResponse) ProtoMessage() {}

func (x *AbortResponse) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AbortResponse.ProtoReflect.Descriptor instead.
func (*AbortResponse) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{12}
}

type GetModelInfoRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetModelInfoRequest) Reset() {
	*x = GetModelInfoRequest{}
	mi := &file_vllm_engine_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelInfoRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelInfoRequest) ProtoMessage() {}

func (x *GetModelInfoRequest) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelInfoRequest.ProtoReflect.Descriptor instead.
func (*GetModelInfoRequest) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{13}
}

type GetModelInfoResponse struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	ModelPath        string                 `protobuf:"bytes,1,opt,name=model_path,json=modelPath,proto3" json:"model_path,omitempty"`
	IsGeneration     bool                   `protobuf:"varint,2,opt,name=is_generation,json=isGeneration,proto3" json:"is_generation,omitempty"`
	MaxContextLength uint32                 `protobuf:"varint,3,opt,name=max_context_length,json=maxContextLength,proto3" json:"max_context_length,omitempty"`
	VocabSize        uint32                 `protobuf:"varint,4,opt,name=vocab_size,json=vocabSize,proto3" json:"vocab_size,omitempty"`
	SupportsVision   bool                   `protobuf:"varint,5,opt,name=supports_vision,json=supportsVision,proto3" json:"supports_vision,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *GetModelInfoResponse) Reset() {
	*x = GetModelInfoResponse{}
	mi := &file_vllm_engine_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetModelInfoResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetModelInfoResponse) ProtoMessage() {}

func (x *GetModelInfoResponse) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetModelInfoResponse.ProtoReflect.Descriptor instead.
func (*GetModelInfoResponse) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{14}
}

func (x *GetModelInfoResponse) GetModelPath() string {
	if x != nil {
		return x.ModelPath
	}
	return ""
}

func (x *GetModelInfoResponse) GetIsGeneration() bool {
	if x != nil {
		return x.IsGeneration
	}
	return false
}

func (x *GetModelInfoResponse) GetMaxContextLength() uint32 {
	if x != nil {
		return x.MaxContextLength
	}
	return 0
}

func (x *GetModelInfoResponse) GetVocabSize() uint32 {
	if x != nil {
		return x.VocabSize
	}
	return 0
}

func (x *GetModelInfoResponse) GetSupportsVision() bool {
	if x != nil {
		return x.SupportsVision
	}
	return false
}

type GetServerInfoRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GetServerInfoRequest) Reset() {
	*x = GetServerInfoRequest{}
	mi := &file_vllm_engine_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetServerInfoRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetServerInfoRequest) ProtoMessage() {}

func (x *GetServerInfoRequest) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetServerInfoRequest.ProtoReflect.Descriptor instead.
func (*GetServerInfoRequest) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{15}
}

type GetServerInfoResponse struct {
	state                protoimpl.MessageState `protogen:"open.v1"`
	ActiveRequests       uint32                 `protobuf:"varint,1,opt,name=active_requests,json=activeRequests,proto3" json:"active_requests,omitempty"`
	IsPaused             bool                   `protobuf:"varint,2,opt,name=is_paused,json=isPaused,proto3" json:"is_paused,omitempty"`
	LastReceiveTimestamp float64                `protobuf:"fixed64,3,opt,name=last_receive_timestamp,json=lastReceiveTimestamp,proto3" json:"last_receive_timestamp,omitempty"`
	UptimeSeconds        float64                `protobuf:"fixed64,4,opt,name=uptime_seconds,json=uptimeSeconds,proto3" json:"uptime_seconds,omitempty"`
	ServerType           string                 `protobuf:"bytes,5,opt,name=server_type,json=serverType,proto3" json:"server_type,omitempty"` // "vllm-grpc"
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *GetServerInfoResponse) Reset() {
	*x = GetServerInfoResponse{}
	mi := &file_vllm_engine_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GetServerInfoResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GetServerInfoResponse) ProtoMessage() {}

func (x *GetServerInfoResponse) ProtoReflect() protoreflect.Message {
	mi := &file_vllm_engine_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GetServerInfoResponse.ProtoReflect.Descriptor instead.
func (*GetServerInfoResponse) Descriptor() ([]byte, []int) {
	return file_vllm_engine_proto_rawDescGZIP(), []int{16}
}

func (x *GetServerInfoResponse) GetActiveRequests() uint32 {
	if x != nil {
		return x.ActiveRequests
	}
	return 0
}

func (x *GetServerInfoResponse) GetIsPaused() bool {
	if x != nil {
		return x.IsPaused
	}
	return false
}

func (x *GetServerInfoResponse) GetLastReceiveTimestamp() float64 {
	if x != nil {
		return x.LastReceiveTimestamp
	}
	return 0
}

func (x *GetServerInfoResponse) GetUptimeSeconds() float64 {
	if x != nil {
		return x.UptimeSeconds
	}
	return 0
}

func (x *GetServerInfoResponse) GetServerType() string {
	if x != nil {
		return x.ServerType
	}
	return ""
}

var File_vllm_engine_proto protoreflect.FileDescriptor

const file_vllm_engine_proto_rawDesc = "" +
	"\n" +
	"\x11vllm_engine.proto\x12\x10vllm.grpc.engine\"\xda\t\n" +
	"\x0eSamplingParams\x12%\n" +
	"\vtemperature\x18\x01 \x01(\x02H\x01R\vtemperature\x88\x01\x01\x12\x13\n" +
	"\x05top_p\x18\x02 \x01(\x02R\x04topP\x12\x13\n" +
	"\x05top_k\x18\x03 \x01(\rR\x04topK\x12\x13\n" +
	"\x05min_p\x18\x04 \x01(\x02R\x04minP\x12+\n" +
	"\x11frequency_penalty\x18\x05 \x01(\x02R\x10frequencyPenalty\x12)\n" +
	"\x10presence_penalty\x18\x06 \x01(\x02R\x0fpresencePenalty\x12-\n" +
	"\x12repetition_penalty\x18\a \x01(\x02R\x11repetitionPenalty\x12\"\n" +
	"\n" +
	"max_tokens\x18\b \x01(\rH\x02R\tmaxTokens\x88\x01\x01\x12\x1d\n" +
	"\n" +
	"min_tokens\x18\t \x01(\rR\tminTokens\x12\x12\n" +
	"\x04stop\x18\n" +
	" \x03(\tR\x04stop\x12$\n" +
	"\x0estop_token_ids\x18\v \x03(\rR\fstopTokenIds\x12.\n" +
	"\x13skip_special_tokens\x18\f \x01(\bR\x11skipSpecialTokens\x12A\n" +
	"\x1dspaces_between_special_tokens\x18\r \x01(\bR\x1aspacesBetweenSpecialTokens\x12\x1d\n" +
	"\n" +
	"ignore_eos\x18\x0e \x01(\bR\tignoreEos\x12\f\n" +
	"\x01n\x18\x0f \x01(\rR\x01n\x12\x1f\n" +
	"\blogprobs\x18\x16 \x01(\x05H\x03R\blogprobs\x88\x01\x01\x12,\n" +
	"\x0fprompt_logprobs\x18\x17 \x01(\x05H\x04R\x0epromptLogprobs\x88\x01\x01\x12\x17\n" +
	"\x04seed\x18\x18 \x01(\x05H\x05R\x04seed\x88\x01\x01\x12:\n" +
	"\x1ainclude_stop_str_in_output\x18\x19 \x01(\bR\x16includeStopStrInOutput\x12N\n" +
	"\n" +
	"logit_bias\x18\x1a \x03(\v2/.vllm.grpc.engine.SamplingParams.LogitBiasEntryR\tlogitBias\x129\n" +
	"\x16truncate_prompt_tokens\x18\x1b \x01(\x05H\x06R\x14truncatePromptTokens\x88\x01\x01\x12!\n" +
	"\vjson_schema\x18\x10 \x01(\tH\x00R\n" +
	"jsonSchema\x12\x16\n" +
	"\x05regex\x18\x11 \x01(\tH\x00R\x05regex\x12\x1a\n" +
	"\agrammar\x18\x12 \x01(\tH\x00R\agrammar\x12'\n" +
	"\x0estructural_tag\x18\x13 \x01(\tH\x00R\rstructuralTag\x12!\n" +
	"\vjson_object\x18\x14 \x01(\bH\x00R\n" +
	"jsonObject\x12<\n" +
	"\x06choice\x18\x15 \x01(\v2\".vllm.grpc.engine.ChoiceConstraintH\x00R\x06choice\x1a<\n" +
	"\x0eLogitBiasEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\x05R\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x02R\x05value:\x028\x01B\f\n" +
	"\n" +
	"constraintB\x0e\n" +
	"\f_temperatureB\r\n" +
	"\v_max_tokensB\v\n" +
	"\t_logprobsB\x12\n" +
	"\x10_prompt_logprobsB\a\n" +
	"\x05_seedB\x19\n" +
	"\x17_truncate_prompt_tokens\",\n" +
	"\x10ChoiceConstraint\x12\x18\n" +
	"\achoices\x18\x01 \x03(\tR\achoices\"R\n" +
	"\x0eTokenizedInput\x12#\n" +
	"\roriginal_text\x18\x01 \x01(\tR\foriginalText\x12\x1b\n" +
	"\tinput_ids\x18\x02 \x03(\rR\binputIds\"\xf4\x01\n" +
	"\x0fGenerateRequest\x12\x1d\n" +
	"\n" +
	"request_id\x18\x01 \x01(\tR\trequestId\x12@\n" +
	"\ttokenized\x18\x02 \x01(\v2 .vllm.grpc.engine.TokenizedInputH\x00R\ttokenized\x12\x14\n" +
	"\x04text\x18\x03 \x01(\tH\x00R\x04text\x12I\n" +
	"\x0fsampling_params\x18\x04 \x01(\v2 .vllm.grpc.engine.SamplingParamsR\x0esamplingParams\x12\x16\n" +
	"\x06stream\x18\x05 \x01(\bR\x06streamB\a\n" +
	"\x05input\"\x9f\x01\n" +
	"\x10GenerateResponse\x12=\n" +
	"\x05chunk\x18\x01 \x01(\v2%.vllm.grpc.engine.GenerateStreamChunkH\x00R\x05chunk\x12@\n" +
	"\bcomplete\x18\x02 \x01(\v2\".vllm.grpc.engine.GenerateCompleteH\x00R\bcompleteB\n" +
	"\n" +
	"\bresponse\"\xa9\x01\n" +
	"\x13GenerateStreamChunk\x12\x1b\n" +
	"\ttoken_ids\x18\x01 \x03(\rR\btokenIds\x12#\n" +
	"\rprompt_tokens\x18\x02 \x01(\rR\fpromptTokens\x12+\n" +
	"\x11completion_tokens\x18\x03 \x01(\rR\x10completionTokens\x12#\n" +
	"\rcached_tokens\x18\x04 \x01(\rR\fcachedTokens\"\xcd\x01\n" +
	"\x10GenerateComplete\x12\x1d\n" +
	"\n" +
	"output_ids\x18\x01 \x03(\rR\toutputIds\x12#\n" +
	"\rfinish_reason\x18\x02 \x01(\tR\ffinishReason\x12#\n" +
	"\rprompt_tokens\x18\x03 \x01(\rR\fpromptTokens\x12+\n" +
	"\x11completion_tokens\x18\x04 \x01(\rR\x10completionTokens\x12#\n" +
	"\rcached_tokens\x18\x05 \x01(\rR\fcachedTokens\"m\n" +
	"\fEmbedRequest\x12\x1d\n" +
	"\n" +
	"request_id\x18\x01 \x01(\tR\trequestId\x12>\n" +
	"\ttokenized\x18\x02 \x01(\v2 .vllm.grpc.engine.TokenizedInputR\ttokenized\"w\n" +
	"\rEmbedResponse\x12\x1c\n" +
	"\tembedding\x18\x01 \x03(\x02R\tembedding\x12#\n" +
	"\rprompt_tokens\x18\x02 \x01(\rR\fpromptTokens\x12#\n" +
	"\rembedding_dim\x18\x03 \x01(\rR\fembeddingDim\"\x14\n" +
	"\x12HealthCheckRequest\"I\n" +
	"\x13HealthCheckResponse\x12\x18\n" +
	"\ahealthy\x18\x01 \x01(\bR\ahealthy\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\"/\n" +
	"\fAbortRequest\x12\x1f\n" +
	"\vrequest_ids\x18\x01 \x03(\tR\n" +
	"requestIds\"\x0f\n" +
	"\rAbortResponse\"\x15\n" +
	"\x13GetModelInfoRequest\"\xd0\x01\n" +
	"\x14GetModelInfoResponse\x12\x1d\n" +
	"\n" +
	"model_path\x18\x01 \x01(\tR\tmodelPath\x12#\n" +
	"\ris_generation\x18\x02 \x01(\bR\fisGeneration\x12,\n" +
	"\x12max_context_length\x18\x03 \x01(\rR\x10maxContextLength\x12\x1d\n" +
	"\n" +
	"vocab_size\x18\x04 \x01(\rR\tvocabSize\x12'\n" +
	"\x0fsupports_vision\x18\x05 \x01(\bR\x0esupportsVision\"\x16\n" +
	"\x14GetServerInfoRequest\"\xdb\x01\n" +
	"\x15GetServerInfoResponse\x12'\n" +
	"\x0factive_requests\x18\x01 \x01(\rR\x0eactiveRequests\x12\x1b\n" +
	"\tis_paused\x18\x02 \x01(\bR\bisPaused\x124\n" +
	"\x16last_receive_timestamp\x18\x03 \x01(\x01R\x14lastReceiveTimestamp\x12%\n" +
	"\x0euptime_seconds\x18\x04 \x01(\x01R\ruptimeSeconds\x12\x1f\n" +
	"\vserver_type\x18\x05 \x01(\tR\n" +
	"serverType2\x92\x04\n" +
	"\n" +
	"VllmEngine\x12S\n" +
	"\bGenerate\x12!.vllm.grpc.engine.GenerateRequest\x1a\".vllm.grpc.engine.GenerateResponse0\x01\x12H\n" +
	"\x05Embed\x12\x1e.vllm.grpc.engine.EmbedRequest\x1a\x1f.vllm.grpc.engine.EmbedResponse\x12Z\n" +
	"\vHealthCheck\x12$.vllm.grpc.engine.HealthCheckRequest\x1a%.vllm.grpc.engine.HealthCheckResponse\x12H\n" +
	"\x05Abort\x12\x1e.vllm.grpc.engine.AbortRequest\x1a\x1f.vllm.grpc.engine.AbortResponse\x12]\n" +
	"\fGetModelInfo\x12%.vllm.grpc.engine.GetModelInfoRequest\x1a&.vllm.grpc.engine.GetModelInfoResponse\x12`\n" +
	"\rGetServerInfo\x12&.vllm.grpc.engine.GetServerInfoRequest\x1a'.vllm.grpc.engine.GetServerInfoResponseB=Z;sigs.k8s.io/gateway-api-inference-extension/pkg/epp/api/genb\x06proto3"

var (
	file_vllm_engine_proto_rawDescOnce sync.Once
	file_vllm_engine_proto_rawDescData []byte
)

func file_vllm_engine_proto_rawDescGZIP() []byte {
	file_vllm_engine_proto_rawDescOnce.Do(func() {
		file_vllm_engine_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_vllm_engine_proto_rawDesc), len(file_vllm_engine_proto_rawDesc)))
	})
	return file_vllm_engine_proto_rawDescData
}

var file_vllm_engine_proto_msgTypes = make([]protoimpl.MessageInfo, 18)
var file_vllm_engine_proto_goTypes = []any{
	(*SamplingParams)(nil),        // 0: vllm.grpc.engine.SamplingParams
	(*ChoiceConstraint)(nil),      // 1: vllm.grpc.engine.ChoiceConstraint
	(*TokenizedInput)(nil),        // 2: vllm.grpc.engine.TokenizedInput
	(*GenerateRequest)(nil),       // 3: vllm.grpc.engine.GenerateRequest
	(*GenerateResponse)(nil),      // 4: vllm.grpc.engine.GenerateResponse
	(*GenerateStreamChunk)(nil),   // 5: vllm.grpc.engine.GenerateStreamChunk
	(*GenerateComplete)(nil),      // 6: vllm.grpc.engine.GenerateComplete
	(*EmbedRequest)(nil),          // 7: vllm.grpc.engine.EmbedRequest
	(*EmbedResponse)(nil),         // 8: vllm.grpc.engine.EmbedResponse
	(*HealthCheckRequest)(nil),    // 9: vllm.grpc.engine.HealthCheckRequest
	(*HealthCheckResponse)(nil),   // 10: vllm.grpc.engine.HealthCheckResponse
	(*AbortRequest)(nil),          // 11: vllm.grpc.engine.AbortRequest
	(*AbortResponse)(nil),         // 12: vllm.grpc.engine.AbortResponse
	(*GetModelInfoRequest)(nil),   // 13: vllm.grpc.engine.GetModelInfoRequest
	(*GetModelInfoResponse)(nil),  // 14: vllm.grpc.engine.GetModelInfoResponse
	(*GetServerInfoRequest)(nil),  // 15: vllm.grpc.engine.GetServerInfoRequest
	(*GetServerInfoResponse)(nil), // 16: vllm.grpc.engine.GetServerInfoResponse
	nil,                           // 17: vllm.grpc.engine.SamplingParams.LogitBiasEntry
}
var file_vllm_engine_proto_depIdxs = []int32{
	17, // 0: vllm.grpc.engine.SamplingParams.logit_bias:type_name -> vllm.grpc.engine.SamplingParams.LogitBiasEntry
	1,  // 1: vllm.grpc.engine.SamplingParams.choice:type_name -> vllm.grpc.engine.ChoiceConstraint
	2,  // 2: vllm.grpc.engine.GenerateRequest.tokenized:type_name -> vllm.grpc.engine.TokenizedInput
	0,  // 3: vllm.grpc.engine.GenerateRequest.sampling_params:type_name -> vllm.grpc.engine.SamplingParams
	5,  // 4: vllm.grpc.engine.GenerateResponse.chunk:type_name -> vllm.grpc.engine.GenerateStreamChunk
	6,  // 5: vllm.grpc.engine.GenerateResponse.complete:type_name -> vllm.grpc.engine.GenerateComplete
	2,  // 6: vllm.grpc.engine.EmbedRequest.tokenized:type_name -> vllm.grpc.engine.TokenizedInput
	3,  // 7: vllm.grpc.engine.VllmEngine.Generate:input_type -> vllm.grpc.engine.GenerateRequest
	7,  // 8: vllm.grpc.engine.VllmEngine.Embed:input_type -> vllm.grpc.engine.EmbedRequest
	9,  // 9: vllm.grpc.engine.VllmEngine.HealthCheck:input_type -> vllm.grpc.engine.HealthCheckRequest
	11, // 10: vllm.grpc.engine.VllmEngine.Abort:input_type -> vllm.grpc.engine.AbortRequest
	13, // 11: vllm.grpc.engine.VllmEngine.GetModelInfo:input_type -> vllm.grpc.engine.GetModelInfoRequest
	15, // 12: vllm.grpc.engine.VllmEngine.GetServerInfo:input_type -> vllm.grpc.engine.GetServerInfoRequest
	4,  // 13: vllm.grpc.engine.VllmEngine.Generate:output_type -> vllm.grpc.engine.GenerateResponse
	8,  // 14: vllm.grpc.engine.VllmEngine.Embed:output_type -> vllm.grpc.engine.EmbedResponse
	10, // 15: vllm.grpc.engine.VllmEngine.HealthCheck:output_type -> vllm.grpc.engine.HealthCheckResponse
	12, // 16: vllm.grpc.engine.VllmEngine.Abort:output_type -> vllm.grpc.engine.AbortResponse
	14, // 17: vllm.grpc.engine.VllmEngine.GetModelInfo:output_type -> vllm.grpc.engine.GetModelInfoResponse
	16, // 18: vllm.grpc.engine.VllmEngine.GetServerInfo:output_type -> vllm.grpc.engine.GetServerInfoResponse
	13, // [13:19] is the sub-list for method output_type
	7,  // [7:13] is the sub-list for method input_type
	7,  // [7:7] is the sub-list for extension type_name
	7,  // [7:7] is the sub-list for extension extendee
	0,  // [0:7] is the sub-list for field type_name
}

func init() { file_vllm_engine_proto_init() }
func file_vllm_engine_proto_init() {
	if File_vllm_engine_proto != nil {
		return
	}
	file_vllm_engine_proto_msgTypes[0].OneofWrappers = []any{
		(*SamplingParams_JsonSchema)(nil),
		(*SamplingParams_Regex)(nil),
		(*SamplingParams_Grammar)(nil),
		(*SamplingParams_StructuralTag)(nil),
		(*SamplingParams_JsonObject)(nil),
		(*SamplingParams_Choice)(nil),
	}
	file_vllm_engine_proto_msgTypes[3].OneofWrappers = []any{
		(*GenerateRequest_Tokenized)(nil),
		(*GenerateRequest_Text)(nil),
	}
	file_vllm_engine_proto_msgTypes[4].OneofWrappers = []any{
		(*GenerateResponse_Chunk)(nil),
		(*GenerateResponse_Complete)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_vllm_engine_proto_rawDesc), len(file_vllm_engine_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   18,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_vllm_engine_proto_goTypes,
		DependencyIndexes: file_vllm_engine_proto_depIdxs,
		MessageInfos:      file_vllm_engine_proto_msgTypes,
	}.Build()
	File_vllm_engine_proto = out.File
	file_vllm_engine_proto_goTypes = nil
	file_vllm_engine_proto_depIdxs = nil
}
